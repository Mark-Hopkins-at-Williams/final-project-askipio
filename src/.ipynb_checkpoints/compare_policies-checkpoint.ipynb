{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Searchless Chess Policies\n",
    "### Alex Kim, CSCI 381\n",
    "\n",
    "searchless_chess.src is copyrighted by DeepMind.\n",
    "\n",
    "Here, I use their library to build simple models.\n",
    "Then, I vary the policy and temperature to do some quick hypothetical ablations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chess\n",
    "import chess.svg\n",
    "from jax import random as jrandom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUuSZBYyWvbf"
   },
   "outputs": [],
   "source": [
    "from searchless_chess.src import tokenizer\n",
    "from searchless_chess.src import training_utils\n",
    "from searchless_chess.src import transformer\n",
    "from searchless_chess.src import utils\n",
    "from searchless_chess.src.engines import engine\n",
    "from searchless_chess.src.engines import neural_engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8w6FnstXMr4"
   },
   "outputs": [],
   "source": [
    "# Create predictor (this cell written by DeepMind)\n",
    "\n",
    "policy = 'action_value'\n",
    "num_return_buckets = 128\n",
    "\n",
    "match policy:\n",
    "  case 'action_value':\n",
    "    output_size = num_return_buckets\n",
    "  case 'behavioral_cloning':\n",
    "    output_size = utils.NUM_ACTIONS\n",
    "  case 'state_value':\n",
    "    output_size = num_return_buckets\n",
    "  case _:\n",
    "    raise ValueError(f'Unknown policy {policy}')\n",
    "\n",
    "predictor_config = transformer.TransformerConfig(\n",
    "    vocab_size=utils.NUM_ACTIONS,\n",
    "    output_size=output_size,\n",
    "    pos_encodings=transformer.PositionalEncodings.LEARNED,\n",
    "    max_sequence_length=tokenizer.SEQUENCE_LENGTH + 2,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    embedding_dim=64,\n",
    "    apply_post_ln=True,\n",
    "    apply_qk_layernorm=False,\n",
    "    use_causal_mask=False,\n",
    ")\n",
    "\n",
    "predictor = transformer.build_transformer_predictor(config=predictor_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZugSBZLXJxn"
   },
   "outputs": [],
   "source": [
    "# Load dummy params\n",
    "\n",
    "params = predictor.initial_params(\n",
    "    rng=jrandom.PRNGKey(0),\n",
    "    targets=np.zeros((1, 1), dtype=np.uint32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize engine\n",
    "\n",
    "def create_engine(policy, num_return_buckets, temperature):\n",
    "    predict_fn = neural_engines.wrap_predict_fn(predictor, params, batch_size=1)\n",
    "    _, return_buckets_values = utils.get_uniform_buckets_edges_values(num_return_buckets)\n",
    "    neural_engine = neural_engines.ENGINE_FROM_POLICY[policy](\n",
    "        return_buckets_values=return_buckets_values,\n",
    "        predict_fn=predict_fn,        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    return neural_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_win_percentages(neural_engine, board):\n",
    "    results = neural_engine.analyse(board)\n",
    "    buckets_log_probs = results['log_probs']\n",
    "    win_probs = np.inner(np.exp(buckets_log_probs), return_buckets_values)\n",
    "    sorted_legal_moves = engine.get_ordered_legal_moves(board)\n",
    "    return win_probs, sorted_legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary policy\n",
    "policies = ['action_value', 'behavioral_cloning', 'state_value']\n",
    "num_return_buckets = 128\n",
    "board = chess.Board()\n",
    "\n",
    "win_percentages = {}\n",
    "for policy in policies:\n",
    "    neural_engine = create_engine(policy, num_return_buckets, temperature = 0.005)\n",
    "    win_probs, sorted_legal_moves = compute_win_percentages(neural_engine, board)\n",
    "    win_percentages[policy] = win_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot win percentages\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(sorted_legal_moves))\n",
    "\n",
    "ax.bar(x - 0.25, win_percentages['action_value'] * 100, label='Action Value')\n",
    "ax.bar(x, win_percentages['behavioral_cloning'] * 100, label='Behavioral Cloning')\n",
    "ax.bar(x + 0.25, win_percentages['state_value'] * 100, label='State Value')\n",
    "\n",
    "ax.set_xlabel('Legal Moves')\n",
    "ax.set_ylabel('Win Percentage')\n",
    "ax.set_title('Win Percentages for Different Policies')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([move.uci() for move in sorted_legal_moves], rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, fix policy and vary temperature\n",
    "policy = 'action_value'\n",
    "num_return_buckets = 128\n",
    "temperatures = [0.005, 0.1, 1.0]\n",
    "board = chess.Board()\n",
    "\n",
    "win_percentages = {}\n",
    "for temp in temperatures:\n",
    "    neural_engine = create_engine(policy, num_return_buckets, temp)\n",
    "    win_probs, sorted_legal_moves = compute_win_percentages(neural_engine, board)\n",
    "    win_percentages[temp] = win_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(sorted_legal_moves))\n",
    "\n",
    "for i, temp in enumerate(temperatures):\n",
    "    ax.bar(x + (i - 1) * 0.25, win_percentages[temp] * 100, label=f'Temperature {temp}')\n",
    "\n",
    "ax.set_xlabel('Legal Moves')\n",
    "ax.set_ylabel('Win Percentage')\n",
    "ax.set_title('Win Percentages for Different Temperatures')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([move.uci() for move in sorted_legal_moves], rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//third_party/deepmind/searchless_chess/src:searchless_chess",
    "kind": "private"
   },
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
